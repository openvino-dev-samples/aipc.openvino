{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a24574f-810d-48f5-b6cf-92297cd21e30",
   "metadata": {},
   "source": [
    "# Lab 4. Retrieval-augmented generation (RAG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e247ed1a-00a6-4005-b362-8dcb7c0eaa19",
   "metadata": {},
   "source": [
    "## 1. Basic Completion and Chat\n",
    "### Download Qwen2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d18203a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from modelscope import snapshot_download\n",
    "llm_model_id = \"snake7gun/Qwen2-7B-Instruct-int4-ov\"\n",
    "llm_local_path  = \"./model/snake7gun/Qwen2-7B-Instruct-int4-ov\"\n",
    "\n",
    "if not Path(llm_local_path).exists():\n",
    "    model_dir = snapshot_download(llm_model_id, cache_dir=\"./model/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7928626d",
   "metadata": {},
   "source": [
    "### Initialize LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a75c915-d4fc-4016-89c6-dba61edea9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id\" in DeployedModel has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in HuggingFaceLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPI has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in TextGenerationInference has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_name\" in OpenVINOLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in OpenVINOLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_id_or_path\" in OpenVINOLLM has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.llms.openvino import OpenVINOLLM\n",
    "\n",
    "ov_config = {\n",
    "    \"PERFORMANCE_HINT\": \"LATENCY\",\n",
    "    \"NUM_STREAMS\": \"1\",\n",
    "    \"CACHE_DIR\": \"\",\n",
    "}\n",
    "\n",
    "def completion_to_prompt(completion):\n",
    "   return f\"<|im_start|>system\\n<|im_end|>\\n<|im_start|>user\\n{completion}<|im_end|>\\n<|im_start|>assistant\\n\"\n",
    "\n",
    "def messages_to_prompt(messages):\n",
    "    prompt = \"\"\n",
    "    for message in messages:\n",
    "        if message.role == \"system\":\n",
    "            prompt += f\"<|im_start|>system\\n{message.content}<|im_end|>\\n\"\n",
    "        elif message.role == \"user\":\n",
    "            prompt += f\"<|im_start|>user\\n{message.content}<|im_end|>\\n\"\n",
    "        elif message.role == \"assistant\":\n",
    "            prompt += f\"<|im_start|>assistant\\n{message.content}<|im_end|>\\n\"\n",
    "\n",
    "    if not prompt.startswith(\"<|im_start|>system\"):\n",
    "        prompt = \"<|im_start|>system\\n\" + prompt\n",
    "\n",
    "    prompt = prompt + \"<|im_start|>assistant\\n\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "ov_llm = OpenVINOLLM(\n",
    "    model_id_or_path=llm_local_path,\n",
    "    context_window=3900,\n",
    "    max_new_tokens=1024,\n",
    "    model_kwargs={\"ov_config\": ov_config},\n",
    "    generate_kwargs={\"pad_token_id\": 32000, \"do_sample\": False, \"temperature\": None, \"top_p\": None},\n",
    "    messages_to_prompt=messages_to_prompt,\n",
    "    completion_to_prompt=completion_to_prompt,\n",
    "    device_map=\"cpu\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6719d-299c-4a11-9f0a-b2ef2d5db716",
   "metadata": {},
   "source": [
    "### Call complete with a prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9aec4ad-efd1-4a56-9343-e8d7cc61ab6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home2/ethan/intel/aipc.openvino/openvino_env/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:623: UserWarning: `do_sample` is set to `False`. However, `top_k` is set to `20` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_k`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " OpenVINO is an open-source toolkit developed by Intel that provides a set of tools and libraries for building high-performance computer vision applications. It includes pre-trained models, inference engines, and development tools to help developers quickly deploy computer vision models on a variety of platforms, including CPUs, GPUs, and FPGAs.\n",
      "OpenVINO supports a wide range of computer vision tasks, including object detection, object recognition, image classification, and more. It also includes support for popular deep learning frameworks such as TensorFlow, Caffe, and ONNX, making it easy to integrate with existing machine learning workflows.\n",
      "One of the key features of OpenVINO is its ability to optimize models for specific hardware platforms, allowing developers to achieve high performance and low latency on a variety of devices. This makes it well-suited for use in a range of applications, from edge devices like smartphones and IoT sensors to data centers and cloud environments.\n",
      "Overall, OpenVINO provides a powerful and flexible platform for developing and deploying computer vision applications, making it a valuable tool for developers working in this field."
     ]
    }
   ],
   "source": [
    "response = ov_llm.stream_complete(\"What is OpenVINO ?\")\n",
    "\n",
    "for r in response:\n",
    "    print(r.delta, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c6cdf6-4358-43aa-a380-2c315f36c228",
   "metadata": {},
   "source": [
    "## 2. Basic RAG (Vector Search, Summarization)\n",
    "### Export Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "536ea7ff-033b-4a53-ba2c-6169c69e47d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_id = \"BAAI/bge-small-zh-v1.5\"\n",
    "embedding_model_path = \"./model/bge-small-zh-v1.5-ov\"\n",
    "\n",
    "if not Path(embedding_model_path).exists():\n",
    "    !optimum-cli export openvino --model {embedding_model_id} --task feature-extraction {embedding_model_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f82691",
   "metadata": {},
   "source": [
    "### Initialize Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e7a768ac-b701-4722-8d88-f1d2561feb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling the model to CPU ...\n"
     ]
    }
   ],
   "source": [
    "from llama_index.embeddings.huggingface_openvino import OpenVINOEmbedding\n",
    "\n",
    "ov_embedding = OpenVINOEmbedding(model_id_or_path=embedding_model_path, device=\"CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84ace02-5bec-4815-a709-0b6423497516",
   "metadata": {},
   "source": [
    "### Basic RAG (Vector Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ed13be16-0364-445e-acc9-d0b466411d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import VectorStoreIndex, Settings\n",
    "\n",
    "Settings.embed_model = ov_embedding\n",
    "Settings.llm = ov_llm\n",
    "\n",
    "reader = SimpleDirectoryReader(\n",
    "    input_files=[\"./examples/text_example_cn.pdf\"]\n",
    ")\n",
    "documents = reader.load_data()\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents,\n",
    ")\n",
    "query_engine = index.as_query_engine(streaming=True, similarity_top_k=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b492fb4-7667-492b-b8f8-0048fc2b592b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "英特尔博锐 Enterprise 系统提供了以下一系列强大且多功能的安全和技术组合：\n",
      "\n",
      "1. **动态信任根**：确保系统的初始启动过程可信，防止恶意软件在系统启动阶段进行攻击。\n",
      "\n",
      "2. **系统管理模式 (SMM)**：提供对系统管理级操作的保护，防止非授权访问和修改。\n",
      "\n",
      "3. **多密钥支持的加密**：通过使用多个密钥，增强了数据加密的安全性，确保敏感信息的安全传输和存储。\n",
      "\n",
      "4. **操作系统内核保护**：保护操作系统的核心部分免受攻击，确保基础系统的稳定性和安全性。\n",
      "\n",
      "5. **KVM 控制的带外管理**：允许远程访问和控制计算机，即使在没有直接物理访问的情况下也能进行管理操作。\n",
      "\n",
      "6. **唯一标识符**：为每个设备提供唯一的识别码，便于管理和追踪。\n",
      "\n",
      "7. **设备历史记录**：记录设备的使用历史和状态变化，有助于故障诊断和维护。\n",
      "\n",
      "8. **可管理性插件**：提供额外的功能和工具，增强设备管理软件的能力，并支持 AIOps（All-In-One Operations）。\n",
      "\n",
      "这些功能结合了强大的安全性和可管理性技术，构成了英特尔博锐平台的基础，为各种规模的组织提供差异化功能。"
     ]
    }
   ],
   "source": [
    "streaming_response = query_engine.query(\"英特尔博锐® Enterprise系统提供哪些功能?\")\n",
    "streaming_response.print_response_stream()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ef4fa99-abaf-40ad-84f8-61d714802d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "相较于英特尔移动移动处理器产品，英特尔酷睿 Ultra Ultra处理器的AI推理性能最高提升了2.5倍。"
     ]
    }
   ],
   "source": [
    "streaming_response = query_engine.query(\"相比英特尔之前的移动处理器产品，英特尔®酷睿™ Ultra处理器的AI推理性能提升了多少？\")\n",
    "streaming_response.print_response_stream()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
